import torch
import numpy as np
from PIL import Image
import torchvision.transforms as transforms

from skimage.segmentation import slic
from skimage.color import label2rgb

class SegmentationPixelArtNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "cell_size": ("INT", {"default":4, "min":1, "max":64, "step":1, "display":"slider"}),
                "n_segments": ("INT", {"default":200, "min":10, "max":2000, "step":10}),
                "compactness": ("FLOAT", {"default":10.0, "min":0.1, "max":100.0, "step":0.1})
            }
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "process"
    CATEGORY = "üòé SnJake/PixelArt"

    def process(self, image: torch.Tensor, cell_size: int, n_segments: int, compactness: float):
        # image: [B,H,W,C], typically B=1
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–Ω–∑–æ—Ä –≤ PIL –¥–ª—è —É–¥–æ–±–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        # –¢–µ–Ω–∑–æ—Ä –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0,1]
        # –§–æ—Ä–º–∞—Ç: [B, H, W, C], C=3
        if image.shape[0] != 1:
            raise ValueError("Only a single image in the batch is supported.")

        img_np = (image[0].cpu().numpy() * 255).astype(np.uint8)  # [H,W,C]
        pil_img = Image.fromarray(img_np)

        # –ò—Å—Ö–æ–¥–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
        w, h = pil_img.size

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–Ω–∏–∑
        # –ß–µ–º –±–æ–ª—å—à–µ cell_size, —Ç–µ–º –º–µ–Ω—å—à–µ –∏—Ç–æ–≥–æ–≤–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –∫—Ä—É–ø–Ω–µ–µ "–ø–∏–∫—Å–µ–ª–∏".
        new_w = max(1, w // cell_size)
        new_h = max(1, h // cell_size)
        small_img = pil_img.resize((new_w, new_h), Image.BICUBIC)  # –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å BILINEAR/BICUBIC

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        small_np = np.array(small_img)  # shape [H',W',3]

        # –ü—Ä–∏–º–µ–Ω—è–µ–º SLIC —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
        # n_segments - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—É–ø–µ—Ä–ø–∏–∫—Å–µ–ª–µ–π, compactness - –±–∞–ª–∞–Ω—Å —Ü–≤–µ—Ç/–ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
        labels = slic(small_np, n_segments=n_segments, compactness=compactness, start_label=0)

        # label2rgb –∑–∞–ø–æ–ª–Ω–∏—Ç –∫–∞–∂–¥—ã–π —Å–µ–≥–º–µ–Ω—Ç —Å—Ä–µ–¥–Ω–∏–º —Ü–≤–µ—Ç–æ–º —Å–µ–≥–º–µ–Ω—Ç–∞
        # –í–∞–∂–Ω–æ: label2rgb –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å–º–µ—à–∏–≤–∞–µ—Ç —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º. –£–∫–∞–∂–µ–º bg_label –∏ alpha=1
        quantized_img = label2rgb(labels, small_np, kind='avg', bg_label=-1, alpha=1)

        # quantized_img —Å–µ–π—á–∞—Å –≤ float64 [0,1], –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ uint8
        quantized_img = (quantized_img * 255).astype(np.uint8)

        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –¥–æ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —á–µ—Ä–µ–∑ nearest neighbor (—á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–∏–∫—Å–µ–ª–∏–∑–∞—Ü–∏—é)
        final_img = Image.fromarray(quantized_img).resize((w, h), Image.NEAREST)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–Ω–∑–æ—Ä —Ñ–æ—Ä–º–∞—Ç–∞ [B,H,W,C] —Å –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º [0,1]
        final_np = np.array(final_img).astype(np.float32) / 255.0
        final_tensor = torch.from_numpy(final_np)[None,]  # [1,H,W,C]

        return (final_tensor,)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —É–∑–µ–ª
NODE_CLASS_MAPPINGS = {
    "SegmentationPixelArtNode": SegmentationPixelArtNode
}
