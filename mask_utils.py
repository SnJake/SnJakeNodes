# file: mask_utils.py

import torch
import torchvision.transforms.functional as TF
import numpy as np

class ResizeAllMasks:
    """
    –ù–æ–¥–∞ –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ —Ç–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –º–∞—Å–∫–∏ (–±–µ–ª–æ–π –∑–æ–Ω—ã), 
    —Å–æ—Ö—Ä–∞–Ω—è—è –∏—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ö–æ–ª—Å—Ç–∞.
    """
    CATEGORY = "üòé SnJake/Masks"
    FUNCTION = "resize_content"
    RETURN_TYPES = ("MASK",)
    RETURN_NAMES = ("masks",)

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "masks": ("MASK",),
                "scale": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.05}),
            }
        }

    def get_bbox_from_mask(self, mask):
        """–ù–∞—Ö–æ–¥–∏—Ç bounding box –¥–ª—è –æ–¥–Ω–æ–π –º–∞—Å–∫–∏."""
        rows = torch.any(mask, axis=1)
        cols = torch.any(mask, axis=0)
        if not torch.any(rows):
            return None
        rmin, rmax = torch.where(rows)[0][[0, -1]]
        cmin, cmax = torch.where(cols)[0][[0, -1]]
        # +1 —á—Ç–æ–±—ã –≤–∫–ª—é—á–∏—Ç—å –∫—Ä–∞–π–Ω–∏–π –ø–∏–∫—Å–µ–ª—å
        return rmin.item(), rmax.item() + 1, cmin.item(), cmax.item() + 1

    def resize_content(self, masks, scale):
        if masks.dim() == 2:
            masks = masks.unsqueeze(0)
            
        original_h, original_w = masks.shape[1], masks.shape[2]
        output_masks = []

        for mask in masks:
            bbox = self.get_bbox_from_mask(mask)

            if bbox is None: # –ï—Å–ª–∏ –º–∞—Å–∫–∞ –ø—É—Å—Ç–∞—è
                output_masks.append(torch.zeros_like(mask))
                continue

            y1, y2, x1, x2 = bbox
            cropped_mask = mask[y1:y2, x1:x2]
            
            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤—ã—Ä–µ–∑–∞–Ω–Ω—É—é —á–∞—Å—Ç—å
            bbox_h, bbox_w = cropped_mask.shape
            new_h, new_w = int(bbox_h * scale), int(bbox_w * scale)

            if new_h == 0 or new_w == 0: # –ï—Å–ª–∏ –º–∞—Å—à—Ç–∞–± —Å–ª–∏—à–∫–æ–º –º–∞–ª
                output_masks.append(torch.zeros_like(mask))
                continue

            # TF.resize —Ç—Ä–µ–±—É–µ—Ç –∫–∞–∫ –º–∏–Ω–∏–º—É–º 3 –∏–∑–º–µ—Ä–µ–Ω–∏—è
            resized_crop = TF.resize(cropped_mask.unsqueeze(0), size=[new_h, new_w], interpolation=TF.InterpolationMode.NEAREST)
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—É—Å—Ç–æ–π —Ö–æ–ª—Å—Ç
            new_canvas = torch.zeros((original_h, original_w), device=masks.device, dtype=masks.dtype)

            # –ù–∞—Ö–æ–¥–∏–º —Ü–µ–Ω—Ç—Ä –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ bbox
            center_y, center_x = (y1 + y2) / 2, (x1 + x2) / 2
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏, —á—Ç–æ–±—ã —Ü–µ–Ω—Ç—Ä—ã —Å–æ–≤–ø–∞–ª–∏
            paste_y1 = int(round(center_y - new_h / 2))
            paste_x1 = int(round(center_x - new_w / 2))

            # –û–±—Ä–µ–∑–∞–µ–º, –µ—Å–ª–∏ –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã (–∫–ª–∏–ø–ø–∏–Ω–≥)
            target_y1 = max(0, paste_y1)
            target_x1 = max(0, paste_x1)
            target_y2 = min(original_h, paste_y1 + new_h)
            target_x2 = min(original_w, paste_x1 + new_w)

            crop_src_y1 = max(0, -paste_y1)
            crop_src_x1 = max(0, -paste_x1)
            crop_src_y2 = crop_src_y1 + (target_y2 - target_y1)
            crop_src_x2 = crop_src_x1 + (target_x2 - target_x1)

            # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Ç–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–∞—Å–∫—É –Ω–∞ –Ω–æ–≤—ã–π —Ö–æ–ª—Å—Ç
            if target_y1 < target_y2 and target_x1 < target_x2:
                new_canvas[target_y1:target_y2, target_x1:target_x2] = resized_crop[0, crop_src_y1:crop_src_y2, crop_src_x1:crop_src_x2]
            
            output_masks.append(new_canvas)

        return (torch.stack(output_masks),)

class BlurImageByMasks:
    """
    –ù–æ–¥–∞ –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ì–∞—É—Å—Å–æ–≤–∞ —Ä–∞–∑–º—ã—Ç–∏—è –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –æ–±–ª–∞—Å—Ç—è–º –º–∞—Å–æ–∫ —Å —Ä–∞—Å—Ç—É—à–µ–≤–∫–æ–π –∫—Ä–∞–µ–≤.
    """
    CATEGORY = "üòé SnJake/Effects"
    FUNCTION = "blur"
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "masks": ("MASK",),
                "blur_radius": ("INT", {"default": 25, "min": 1, "max": 201, "step": 2, "tooltip": "–°–∏–ª–∞ —Ä–∞–∑–º—ã—Ç–∏—è –¥–ª—è —Å–∞–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."}),
                "feather_amount": ("INT", {"default": 15, "min": 0, "max": 201, "step": 2, "tooltip": "–°–∏–ª–∞ —Ä–∞–∑–º—ã—Ç–∏—è –∫—Ä–∞–µ–≤ –º–∞—Å–∫–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–ª–∞–≤–Ω–æ–≥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞."}),
            }
        }

    def blur(self, image, masks, blur_radius, feather_amount):
        # 1. –ì–æ—Ç–æ–≤–∏–º –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–∑–º—ã—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if blur_radius % 2 == 0: blur_radius += 1
        
        image_bchw = image.permute(0, 3, 1, 2)
        blurred_image_bchw = TF.gaussian_blur(image_bchw, kernel_size=(blur_radius, blur_radius))
        blurred_image = blurred_image_bchw.permute(0, 2, 3, 1)

        # 2. –ì–æ—Ç–æ–≤–∏–º –º–∞—Å–∫—É (—Å —Ä–∞—Å—Ç—É—à–µ–≤–∫–æ–π)
        if masks.dim() == 2:
            masks = masks.unsqueeze(0)
        
        # –°–æ–≤–º–µ—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        if masks.shape[0] != image.shape[0]:
            if masks.shape[0] == 1:
                masks = masks.repeat(image.shape[0], 1, 1)
            else:
                 raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –±—ã—Ç—å —Ä–∞–≤–Ω—ã–º 1.")

        blended_mask = masks
        if feather_amount > 0:
            if feather_amount % 2 == 0: feather_amount += 1
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª –¥–ª—è blur-—Ñ—É–Ω–∫—Ü–∏–∏: [B, H, W] -> [B, 1, H, W]
            feather_mask = masks.unsqueeze(1)
            blurred_mask_bchw = TF.gaussian_blur(feather_mask, kernel_size=(feather_amount, feather_amount))
            # –£–±–∏—Ä–∞–µ–º –∫–∞–Ω–∞–ª –æ–±—Ä–∞—Ç–Ω–æ: [B, 1, H, W] -> [B, H, W]
            blended_mask = blurred_mask_bchw.squeeze(1)
        
        # 3. –°–º–µ—à–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–º—ã—Ç—É—é –º–∞—Å–∫—É
        mask_expanded = blended_mask.unsqueeze(-1)
        output_image = image * (1 - mask_expanded) + blurred_image * mask_expanded
        
        return (output_image,)

class OverlayImageByMasks:
    """
    –ù–æ–¥–∞ –¥–ª—è –Ω–∞–ª–æ–∂–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –º–∞—Å–∫–µ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∏ —Ä—É—á–Ω—ã–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ–º, 
    –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å—é –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞.
    """
    CATEGORY = "üòé SnJake/Masks"
    FUNCTION = "overlay"
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "base_image": ("IMAGE",),
                "overlay_image": ("IMAGE",),
                "masks": ("MASK",),
                "scale": ("FLOAT", {"default": 1.0, "min": 0.1, "max": 5.0, "step": 0.05}),
                "opacity": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}),
            }
        }

    def get_bbox_from_mask(self, mask):
        rows = torch.any(mask, axis=1)
        cols = torch.any(mask, axis=0)
        if not torch.any(rows):
            return None
        rmin, rmax = torch.where(rows)[0][[0, -1]]
        cmin, cmax = torch.where(cols)[0][[0, -1]]
        return rmin.item(), rmax.item(), cmin.item(), cmax.item()

    def overlay(self, base_image, overlay_image, masks, scale, opacity):
        if overlay_image.shape[0] != 1:
            raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–¥–Ω–∏–º (—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ 1).")
        
        output_image = base_image.clone()
        base_has_alpha = base_image.shape[-1] == 4
        
        if masks.dim() == 2:
            masks = masks.unsqueeze(0)
            
        if masks.shape[0] != base_image.shape[0]:
            if masks.shape[0] == 1:
                masks = masks.repeat(base_image.shape[0], 1, 1)
            else:
                raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–∞—Å–æ–∫ –¥–æ–ª–∂–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –±—ã—Ç—å —Ä–∞–≤–Ω—ã–º 1.")

        overlay_bchw = overlay_image.permute(0, 3, 1, 2)
        overlay_has_alpha = overlay_bchw.shape[1] == 4

        for i in range(base_image.shape[0]):
            mask = masks[i]
            bbox = self.get_bbox_from_mask(mask)
            if bbox is None:
                continue

            y1, y2, x1, x2 = bbox
            bbox_h, bbox_w = y2 - y1 + 1, x2 - x1 + 1
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –º–∞—Å—à—Ç–∞–±
            scaled_h, scaled_w = int(bbox_h * scale), int(bbox_w * scale)
            if scaled_h == 0 or scaled_w == 0: continue

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –æ–≤–µ—Ä–ª–µ–π
            resized_overlay_bchw = TF.resize(overlay_bchw, size=[scaled_h, scaled_w], antialias=True)
            resized_overlay = resized_overlay_bchw.permute(0, 2, 3, 1).squeeze(0)

            # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –æ—Ç–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–≤–µ—Ä–ª–µ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ bbox
            center_x, center_y = x1 + bbox_w // 2, y1 + bbox_h // 2
            paste_x1, paste_y1 = center_x - scaled_w // 2, center_y - scaled_h // 2
            
            # --- –õ–æ–≥–∏–∫–∞ –æ–±—Ä–µ–∑–∫–∏ (Clipping) ---
            # –û–±–ª–∞—Å—Ç—å –Ω–∞ –±–∞–∑–æ–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏, –∫—É–¥–∞ –±—É–¥–µ–º –≤—Å—Ç–∞–≤–ª—è—Ç—å
            img_h, img_w = base_image.shape[1], base_image.shape[2]
            target_x1 = max(0, paste_x1)
            target_y1 = max(0, paste_y1)
            target_x2 = min(img_w, paste_x1 + scaled_w)
            target_y2 = min(img_h, paste_y1 + scaled_h)

            # –û–±–ª–∞—Å—Ç—å –Ω–∞ –æ–≤–µ—Ä–ª–µ–µ, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º –≤—ã—Ä–µ–∑–∞—Ç—å
            crop_x1 = max(0, -paste_x1)
            crop_y1 = max(0, -paste_y1)
            crop_x2 = crop_x1 + (target_x2 - target_x1)
            crop_y2 = crop_y1 + (target_y2 - target_y1)

            if target_x1 >= target_x2 or target_y1 >= target_y2: continue
            
            # –í—ã—Ä–µ–∑–∞–µ–º –Ω—É–∂–Ω—ã–µ —á–∞—Å—Ç–∏
            base_region = output_image[i, target_y1:target_y2, target_x1:target_x2, :]
            mask_region = mask[target_y1:target_y2, target_x1:target_x2].unsqueeze(-1)
            overlay_cropped = resized_overlay[crop_y1:crop_y2, crop_x1:crop_x2, :]

            # --- –õ–æ–≥–∏–∫–∞ —Å–º–µ—à–∏–≤–∞–Ω–∏—è —Å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–º ---
            overlay_rgb = overlay_cropped[..., :3]
            if overlay_has_alpha:
                overlay_alpha = overlay_cropped[..., 3:4]
            else:
                overlay_alpha = torch.ones_like(overlay_rgb[..., :1])
            
            # –§–∏–∫—Å –æ—à–∏–±–∫–∏: —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å RGB –∫–∞–Ω–∞–ª–∞–º–∏ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏ —Å–º–µ—à–∏–≤–∞–Ω–∏–∏
            base_rgb_region = base_region[..., :3]

            final_alpha_mask = overlay_alpha * mask_region * opacity
            
            blended_rgb = base_rgb_region * (1.0 - final_alpha_mask) + overlay_rgb * final_alpha_mask

            # –ï—Å–ª–∏ —É –±–∞–∑–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å—Ç—å –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª, —Å–æ—Ö—Ä–∞–Ω–∏–º –µ–≥–æ
            if base_has_alpha:
                 output_image[i, target_y1:target_y2, target_x1:target_x2, :3] = blended_rgb
                 # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è —Å–º–µ—à–∏–≤–∞–Ω–∏—è –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–æ–≤, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            else:
                 output_image[i, target_y1:target_y2, target_x1:target_x2, :] = blended_rgb
            
        return (output_image,)
