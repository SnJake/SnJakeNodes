import torch
import numpy as np
import cv2
from PIL import Image, ImageEnhance

class ImageAdjustmentNode:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                # –ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–º–µ—â–∞—Ç—å –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∫—Ä–∞—Å–Ω—ã–º –∏ —Å–∏–Ω–∏–º.
                # –¢–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∫–∞–∫ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ (—Å–æ–≥—Ä–µ–≤), —Ç–∞–∫ –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ (–æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ) –∑–Ω–∞—á–µ–Ω–∏—è.
                "temperature": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "hue": ("FLOAT", {
                    "default": 0,
                    "min": -180,
                    "max": 180,
                    "step": 1
                }),
                "brightness": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "contrast": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "saturation": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "gamma": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.1,
                    "max": 5.0,
                    "step": 0.1
                }),
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–Ω–æ–≤
                "midtone_red": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "midtone_green": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
                "midtone_blue": ("FLOAT", {
                    "default": 0,
                    "min": -100,
                    "max": 100,
                    "step": 1
                }),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "color_correct"
    CATEGORY = "üòé SnJake/Adjustment"

    def color_correct(self, image: torch.Tensor, temperature: float, hue: float, brightness: float, contrast: float,
                      saturation: float, gamma: float, midtone_red: float, midtone_green: float, midtone_blue: float):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É [B, H, W, 3]
        if image.ndim != 4 or image.shape[-1] != 3:
            raise ValueError("–í—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —Ñ–æ—Ä–º—É [B, H, W, 3] (RGB)")

        original_device = image.device
        image = image.cpu().float()  # –†–∞–±–æ—Ç–∞–µ–º –Ω–∞ CPU

        batch_size, height, width, channels = image.shape
        result = torch.zeros_like(image)

        # –ü—Ä–∏–≤–æ–¥–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫ —É–¥–æ–±–Ω—ã–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º
        brightness_factor = (brightness / 100.0) + 1.0  # [0, 2]
        contrast_factor = (contrast / 100.0) + 1.0        # [0, 2]
        saturation_factor = (saturation / 100.0) + 1.0      # [0, 2]
        hue_shift = hue  # –≤ –≥—Ä–∞–¥—É—Å–∞—Ö
        gamma = max(gamma, 1e-8)  # –∏–∑–±–µ–≥–∞–µ–º 0 –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö

        # –¶–≤–µ—Ç–æ–≤–æ–π –±–∞–ª–∞–Ω—Å –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–Ω–æ–≤ (–ø–µ—Ä–µ–≤–æ–¥–∏–º [-100,100] –≤ [-1,1])
        midtone_red   = midtone_red   / 100.0
        midtone_green = midtone_green / 100.0
        midtone_blue  = midtone_blue  / 100.0

        for b in range(batch_size):
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ç–µ–Ω–∑–æ—Ä –≤ numpy-–º–∞—Å—Å–∏–≤ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –≤ –¥–∏–∞–ø–∞–∑–æ–Ω [0, 255]
            tensor_image = image[b].numpy()
            tensor_image = np.clip(tensor_image, 0, 1)
            tensor_image = (tensor_image * 255).astype(np.uint8)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PIL Image –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —è—Ä–∫–æ—Å—Ç–∏ –∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            pil_image = Image.fromarray(tensor_image)

            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —è—Ä–∫–æ—Å—Ç–∏
            brightness_factor_clipped = max(brightness_factor, 0.0)
            enhancer = ImageEnhance.Brightness(pil_image)
            pil_image = enhancer.enhance(brightness_factor_clipped)

            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
            contrast_factor_clipped = max(contrast_factor, 0.0)
            enhancer = ImageEnhance.Contrast(pil_image)
            pil_image = enhancer.enhance(contrast_factor_clipped)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ numpy-–º–∞—Å—Å–∏–≤ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
            modified_image = np.array(pil_image).astype(np.float32) / 255.0

            # --- –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã ---
            # –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞: –ø—Ä–∏–º–µ–Ω—è–µ–º –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—ã–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ R –∏ B.
            # –î–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã (—Ç–µ–ø–ª–µ–µ) —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º R –∏ —É–º–µ–Ω—å—à–∞–µ–º B,
            # –¥–ª—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π (—Ö–æ–ª–æ–¥–Ω–µ–µ) ‚Äì –Ω–∞–æ–±–æ—Ä–æ—Ç.
            if temperature != 0:
                # –í—ã–±–∏—Ä–∞–µ–º –º–∞—Å—à—Ç–∞–±. –î–µ–ª–∏–º –Ω–∞ 200, —á—Ç–æ–±—ã –ø—Ä–∏ –º–∞–∫—Å–∏–º—É–º–µ ¬±100 –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –±—ã–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–º–∏.
                t = temperature / 200.0  
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É: —É–º–Ω–æ–∂–∞–µ–º –∫—Ä–∞—Å–Ω—ã–π –∏ —Å–∏–Ω–∏–π –∫–∞–Ω–∞–ª—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ.
                r, g, b_channel = cv2.split(modified_image)
                r = np.clip(r * (1 + t), 0, 1)
                b_channel = np.clip(b_channel * (1 - t), 0, 1)
                modified_image = cv2.merge((r, g, b_channel))
            # -----------------------------------------

            # –ì–∞–º–º–∞-–∫–æ—Ä—Ä–µ–∫—Ü–∏—è (–ø—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–µ–ø–µ–Ω—å gamma)
            if abs(gamma - 1.0) > 1e-3:
                modified_image = np.power(modified_image, gamma)
                modified_image = np.clip(modified_image, 0, 1)

            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏ –∏ –æ—Ç—Ç–µ–Ω–∫–∞ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ HSV
            hsv_img = cv2.cvtColor(modified_image, cv2.COLOR_RGB2HSV)
            # –ù–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç—å
            if saturation != 0:
                hsv_img[:, :, 1] = np.clip(hsv_img[:, :, 1] * saturation_factor, 0, 1)
            # –û—Ç—Ç–µ–Ω–æ–∫ (hue). –ü–æ—Å–∫–æ–ª—å–∫—É hue —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ [0,1], —Å–º–µ—â–∞–µ–º –Ω–∞ hue/360
            if hue != 0:
                hsv_img[:, :, 0] = (hsv_img[:, :, 0] + (hue_shift / 360.0)) % 1.0
            modified_image = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2RGB)
            modified_image = np.clip(modified_image, 0, 1)

            # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞ –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–Ω–æ–≤
            if any([midtone_red, midtone_green, midtone_blue]):
                # –í—ã—á–∏—Å–ª—è–µ–º —è—Ä–∫–æ—Å—Ç—å (luminance) –∏ —Å–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–Ω–æ–≤
                luminance = cv2.cvtColor(modified_image, cv2.COLOR_RGB2GRAY)
                midtone_mask = self.create_midtone_mask(luminance)
                midtone_mask = np.stack([midtone_mask] * 3, axis=2)
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–¥–≤–∏–≥ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–∞–Ω–∞–ª—É
                color_shift = np.zeros_like(modified_image)
                color_shift[:, :, 0] = midtone_red
                color_shift[:, :, 1] = midtone_green
                color_shift[:, :, 2] = midtone_blue
                modified_image = np.clip(modified_image + color_shift * midtone_mask, 0, 1)

            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ç–µ–Ω–∑–æ—Ä
            result[b] = torch.from_numpy(modified_image).to(torch.float32)

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ
        result = result.to(original_device)
        return (result,)

    def create_midtone_mask(self, luminance: np.ndarray) -> np.ndarray:
        """
        –°–æ–∑–¥–∞–µ—Ç –º–∞—Å–∫—É –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–Ω–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —è—Ä–∫–æ—Å—Ç–∏.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≥–∞—É—Å—Å–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏—è, —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ 0.5.
        """
        luminance = np.clip(luminance, 0, 1)
        midtone_mask = np.exp(-4 * ((luminance - 0.5) ** 2))
        return midtone_mask
