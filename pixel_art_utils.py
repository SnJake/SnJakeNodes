# filename: pixel_art_utils.py
import torch
import numpy as np
#from PIL import Image # PIL –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω –∑–¥–µ—Å—å
import kornia.color as kc # –î–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ LAB/Luminance –≤ ReplacePalette
import traceback
import math # –î–ª—è math.isfinite –≤ calculate_dbi

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –æ–¥–∏–Ω —Ä–∞–∑
# –õ—É—á—à–µ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤ –º–æ–º–µ–Ω—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —É–∑–ª–∞,
# —Ç–∞–∫ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å CPU/GPU –≤ ComfyUI
def get_torch_device():
    if torch.cuda.is_available():
        return torch.device("cuda")
    # elif torch.backends.mps.is_available(): # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è MacOS
    #     return torch.device("mps")
    else:
        return torch.device("cpu")

# --- –ò–ú–ü–û–†–¢–´ –ò–ó –û–ë–©–ï–ô –õ–û–ì–ò–ö–ò ---
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ pixelart –∏ —Ñ–∞–π–ª pixel_art_logic.py –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, —á—Ç–æ –∏ —ç—Ç–æ—Ç —Ñ–∞–π–ª
LOGIC_IMPORTED = False
try:
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø–∞–ª–∏—Ç—Ä—ã –∏–∑ quantization.py
    # (–æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç COLOR_SPACE_RANGES –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏/–ø—Ä–æ–µ–∫—Ü–∏–∏)
    from .pixelart.quantization import (
        run_color_quantization,
        apply_fixed_palette,
        apply_fixed_palette_get_labels
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã (kmeans, sq) –≤—ã–∑—ã–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ run_color_quantization
    )
    # –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ü–≤–µ—Ç–æ–º –∏–∑ color_utils.py
    from .pixelart.color_utils import (
        to_quantize_space,
        from_quantize_space,
        convert_palette_to_string,
        calculate_dbi # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    )
    # –õ–æ–≥–∏–∫–∞ –¥–∏–∑–µ—Ä–∏–Ω–≥–∞ –∏–∑ dithering.py
    from .pixelart.dithering import (
        apply_dithering,
        DIFFUSION_PATTERNS,
        ORDERED_PATTERNS
    )
    LOGIC_IMPORTED = True
    print("Successfully imported PixelArt logic modules for Utils.")
except ImportError as e:
    print("*"*80)
    print("[ERROR] Failed to import from pixelart logic modules!")
    print(f"Error details: {e}")
    print("Please ensure the 'pixelart' folder with logic files exists.")
    print("Nodes requiring this logic (ExtractPaletteNode, ApplyPaletteNode, ReplacePaletteColorsNode) will likely fail.")
    print("*"*80)
    traceback.print_exc()
    raise ImportError("Failed to load PixelArt logic modules.") from e


# --- –ù–æ–≤—ã–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ç–∏–ø ---
PALETTE = "*" # –≠—Ç–æ –±—É–¥–µ—Ç —Ç–µ–Ω–∑–æ—Ä [N, 3]

# --- –£–∑–µ–ª –ò–∑–≤–ª–µ—á–µ–Ω–∏—è –ü–∞–ª–∏—Ç—Ä—ã ---
class ExtractPaletteNode:
    CATEGORY = "üòé SnJake/PixelArt"
    FUNCTION = "extract_palette"
    RETURN_TYPES = (PALETTE, "STRING") # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –ø–∞–ª–∏—Ç—Ä—ã –∏ HEX-—Å—Ç—Ä–æ–∫—É
    RETURN_NAMES = ("palette_tensor", "palette_hex")

    @classmethod
    def INPUT_TYPES(cls):
        # –ù–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —É–∑–µ–ª, –µ—Å–ª–∏ –ª–æ–≥–∏–∫–∞ –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∞—Å—å
        if not LOGIC_IMPORTED:
             return {"required": {"error": ("STRING", {"default": "PixelArt logic failed to load", "forceInput": True, "hidden":True})}}

        # –î–æ–±–∞–≤–∏–º SQ –≤ —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–¥–æ–≤
        quant_methods = ["kmeans", "median_cut", "octree", "SQ"] # Wu —É–±—Ä–∞–Ω, SQ –¥–æ–±–∞–≤–ª–µ–Ω

        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ-–¥–æ–Ω–æ—Ä –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–ª–∏—Ç—Ä—ã."}),
                "num_colors": ("INT", {"default": 16, "min": 2, "max": 256, "step": 1, "display": "slider"}),
                "method": (quant_methods, {"default": "kmeans", "tooltip": "–ú–µ—Ç–æ–¥ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–∞–ª–∏—Ç—Ä—ã."}), # –û–±–Ω–æ–≤–ª–µ–Ω —Å–ø–∏—Å–æ–∫
                "color_space": (["RGB", "LAB", "YCbCr", "HSV"], {"default": "LAB", "tooltip": "–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –ø—Ä–∏ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–∏. LAB/YCbCr —á–∞—Å—Ç–æ –ª—É—á—à–µ."}), # –û–±–Ω–æ–≤–ª–µ–Ω tooltip
                "min_pixel_area": ("INT", {"default": 1, "min": 1, "max": 1000, "step": 1, "display": "slider", "tooltip": "–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ –ø–∏–∫—Å–µ–ª–µ–π –¥–ª—è —Ü–≤–µ—Ç–∞ –≤ –ø–∞–ª–∏—Ç—Ä–µ (1=–≤—ã–∫–ª)."}), # –û–±–Ω–æ–≤–ª–µ–Ω tooltip
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –º–µ—Ç–æ–¥–æ–≤
                "max_kmeans_iter": ("INT", {"default": 20, "min": 1, "max": 100, "step": 1}),
                "sq_iterations_factor": ("INT", {"default": 2, "min": 1, "max": 50, "step": 1,
                     "tooltip": "SQ Iterations = factor * number_of_pixels"
                }),
                "sq_learning_rate_initial": ("FLOAT", { # –ò–°–ü–†–ê–í–õ–ï–ù–û
                    "default": 0.1, "min": 1e-4, "max": 1.0, "step": 1e-3, "round": 0.0001,
                    "tooltip": "Initial learning rate for SQ"
                }),
                "sq_learning_rate_decay_time": ("INT", { # –ò–°–ü–†–ê–í–õ–ï–ù–û
                    "default": 10000, "min": 100, "max": 1000000, "step": 100,
                     "tooltip": "Time constant (t0) for SQ learning rate decay"
                }),
            }
        }

    def extract_palette(self, image, num_colors, method, color_space, min_pixel_area,
                        max_kmeans_iter, # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è K-Means
                        sq_iterations_factor, # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è SQ
                        sq_learning_rate_initial, # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è SQ
                        sq_learning_rate_decay_time # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è SQ
                        ):

        device = image.device if isinstance(image, torch.Tensor) else get_torch_device()
        print(f"[ExtractPaletteNode] Input image initial device: {image.device}, Target device: {device}")

        if not LOGIC_IMPORTED:
             print("[ExtractPaletteNode] ERROR: PixelArt logic modules failed to load.")
             return (None, "Error: PixelArt logic modules failed to load")
        if image is None:
            return (None, "Error: No input image")

        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
        try:
            image = image.to(device) # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ —Ü–µ–ª–µ–≤–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            print(f"[ExtractPaletteNode] Input image moved to device: {image.device}")
            image = image.clamp(0, 1)
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            if image.dim() == 4 and image.shape[0] > 1:
                 print(f"[ExtractPaletteNode] Warning: Input batch size is {image.shape[0]}. Using only the first image for palette extraction.")
                 image_chw = image[0:1].permute(0, 3, 1, 2).float() # (1, C, H, W), –∏—Å–ø–æ–ª—å–∑—É–µ–º float
            elif image.dim() == 4:
                 image_chw = image.permute(0, 3, 1, 2).float() # (1, C, H, W)
            else:
                raise ValueError(f"Unexpected input image shape: {image.shape}")

            batch_size, channels, height, width = image_chw.shape
            if channels != 3:
                 raise ValueError(f"ExtractPaletteNode requires RGB input (3 channels), got {channels}")

        except Exception as e:
             print(f"[ExtractPaletteNode] Error during image preparation: {e}")
             traceback.print_exc()
             return (None, f"Error: Image Prep Failed - {e}")


        # --- –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–±–æ—á–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ ---
        # (–¢–∞ –∂–µ –ª–æ–≥–∏–∫–∞, —á—Ç–æ –∏ –≤ PixelArtNode)
        processing_space = color_space
        method_clean = method.strip().lower()
        is_metric_sensitive_method = method_clean in ["kmeans", "median_cut", "sq"] # –ú–µ—Ç–æ–¥—ã, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ –∫ –º–µ—Ç—Ä–∏–∫–µ
        if color_space == "HSV" and is_metric_sensitive_method:
             print(f"[ExtractPaletteNode] Warning: Using HSV with '{method}' is unreliable. Forcing RGB for calculations.")
             processing_space = "RGB"
        # Octree fallback (kmeans) —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ processing_space
        elif method_clean == "octree" and color_space != "RGB":
             print(f"[ExtractPaletteNode] Note: Method '{method}' (fallback to kmeans) will use {color_space} space as requested.")
             # Fallback (kmeans) –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ

        print(f"[ExtractPaletteNode] Extracting palette using '{method_clean}' in {processing_space} space (User selected: {color_space}).")

        final_centroids_rgb = None
        try:
            # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ä–∞–±–æ—á–µ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–∞ –≤—Ö–æ–¥–µ float
            img_in_processing_space = to_quantize_space(image_chw.float(), processing_space)

            # 2. –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è
            quant_params = {
                "num_colors": num_colors,
                "method": method_clean,
                "min_pixel_area": min_pixel_area,
                "processing_space": processing_space,
                "auto_num_colors": False, # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ K –∑–¥–µ—Å—å
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤
                "kmeans_max_iter": max_kmeans_iter,
                "sq_iterations_factor": sq_iterations_factor,
                "sq_learning_rate_initial": sq_learning_rate_initial,
                "sq_learning_rate_decay_time": sq_learning_rate_decay_time
            }

            # 3. –í—ã–ø–æ–ª–Ω—è–µ–º –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤
            _, final_centroids_in_space = run_color_quantization(
                img_in_processing_space, **quant_params # –ü–µ—Ä–µ–¥–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            )

            # 4. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ RGB [0,1]
            if final_centroids_in_space is not None and final_centroids_in_space.shape[0] > 0:
                 # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                 centroids_expanded = final_centroids_in_space.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)
                 final_centroids_rgb = from_quantize_space(centroids_expanded, processing_space)
                 final_centroids_rgb = final_centroids_rgb.squeeze().clamp(0, 1) # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏ –∑–∞–∂–∏–º–∞–µ–º
                 # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç 2D (N, C)
                 if final_centroids_rgb.ndim == 1:
                      final_centroids_rgb = final_centroids_rgb.unsqueeze(0)
            else:
                 print("[ExtractPaletteNode] Warning: Quantization did not return valid centroids.")
                 final_centroids_rgb = None

        except Exception as e:
            print(f"[ExtractPaletteNode] Error during palette extraction: {e}")
            traceback.print_exc()
            return (None, f"Error: {e}")

        # 5. –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥
        if final_centroids_rgb is None or final_centroids_rgb.shape[0] == 0:
            return (None, "Error: Failed to extract palette")

        palette_tensor = final_centroids_rgb.float() # –í–æ–∑–≤—Ä–∞—â–∞–µ–º float
        palette_hex = convert_palette_to_string(palette_tensor) # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ logic

        print(f"[ExtractPaletteNode] Extracted palette with {palette_tensor.shape[0]} colors.")
        return (palette_tensor, palette_hex)


# --- –£–∑–µ–ª –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ü–∞–ª–∏—Ç—Ä—ã ---
class ApplyPaletteNode:
    CATEGORY = "üòé SnJake/PixelArt/Utils" # –£—Ç–æ—á–Ω–∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    FUNCTION = "apply_palette"
    RETURN_TYPES = ("IMAGE",)

    @classmethod
    def INPUT_TYPES(cls):
        if not LOGIC_IMPORTED:
             return {"required": {"error": ("STRING", {"default": "PixelArt logic failed to load", "forceInput": True, "hidden":True})}}

        dither_patterns = ["No Dithering"] + list(DIFFUSION_PATTERNS.keys()) + list(ORDERED_PATTERNS.keys()) + ["WhiteNoise"]

        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "–¶–µ–ª–µ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–æ–±—ã—á–Ω–æ –ø–æ—Å–ª–µ PixelArtNode –±–µ–∑ –∫–≤–∞–Ω—Ç–æ–≤–∞–Ω–∏—è)."}),
                "palette_tensor": (PALETTE, {"tooltip": "–ü–∞–ª–∏—Ç—Ä–∞ (—Ç–µ–Ω–∑–æ—Ä [N, 3] RGB 0-1) –æ—Ç ExtractPaletteNode."}),
                "dithering": ("BOOLEAN", {"default": True, "tooltip": "–ü—Ä–∏–º–µ–Ω–∏—Ç—å –¥–∏–∑–µ—Ä–∏–Ω–≥ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ —Å –ø–∞–ª–∏—Ç—Ä–æ–π."}),
                "dither_pattern": (dither_patterns, {"default": "Floyd-Steinberg"}),
                "dither_strength": ("FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 0.05}),
                "color_space": (["RGB", "LAB", "YCbCr", "HSV"], {"default": "LAB", "tooltip": "–ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Ü–≤–µ—Ç–∞ –ø—Ä–∏ –ú–≠–ü–ü–ò–ù–ì–ï (–¥–∏–∑–µ—Ä–∏–Ω–≥ –≤—Å–µ–≥–¥–∞ –≤ RGB). LAB/YCbCr —á–∞—Å—Ç–æ –ª—É—á—à–µ."}), # –£—Ç–æ—á–Ω–∏–ª–∏ tooltip
                "color_distance_threshold": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "–¢–æ–ª—å–∫–æ –¥–ª—è Error Diffusion –¥–∏–∑–µ—Ä–∏–Ω–≥–∞. –ü–æ—Ä–æ–≥ –µ–≤–∫–ª–∏–¥–æ–≤–∞ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –æ—à–∏–±–∫–∏ (0 = –≤—Å–µ–≥–¥–∞)."}),
            }
        }

    def apply_palette(self, image, palette_tensor, dithering, dither_pattern, dither_strength, color_space, color_distance_threshold):
        device = image.device if isinstance(image, torch.Tensor) else get_torch_device()
        print(f"[ApplyPaletteNode] Input image initial device: {image.device}, Target device: {device}")

        if not LOGIC_IMPORTED:
             print("[ApplyPaletteNode] ERROR: PixelArt logic modules failed to load.")
             return (image,) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª

        if image is None:
            print("[ApplyPaletteNode] Error: No input image.")
            return (None,)
        if palette_tensor is None or not isinstance(palette_tensor, torch.Tensor) or palette_tensor.ndim != 2 or palette_tensor.shape[1] != 3:
            print(f"[ApplyPaletteNode] Error: Invalid palette input. Expected tensor [N, 3], got: {type(palette_tensor)}")
            return (image,)

        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ---
        image = image.to(device)
        palette_tensor = palette_tensor.to(device)
        print(f"[ApplyPaletteNode] Inputs moved to device: {device}")

        image_chw = image.permute(0, 3, 1, 2).float().clamp(0, 1) # B, C, H, W - –∏—Å–ø–æ–ª—å–∑—É–µ–º float
        palette_rgb = palette_tensor.float().clamp(0, 1) # N, C - –∏—Å–ø–æ–ª—å–∑—É–µ–º float

        print(f"[ApplyPaletteNode] Applying palette with {palette_rgb.shape[0]} colors. Dithering: {dithering} ({dither_pattern} / Strength: {dither_strength:.2f}). Mapping space: {color_space}.")

        result_image_chw = torch.zeros_like(image_chw)

        # --- –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞: –î–∏–∑–µ—Ä–∏–Ω–≥ –∏–ª–∏ –ü—Ä—è–º–æ–µ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ ---
        use_dither = dithering and dither_pattern != "No Dithering" and dither_strength > 0
        if use_dither:
            # --- –î–∏–∑–µ—Ä–∏–Ω–≥ (–≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ RGB) ---
            print("  - Applying dithering...")
            try:
                # apply_dithering –æ–∂–∏–¥–∞–µ—Ç RGB –∏—Å—Ç–æ—á–Ω–∏–∫ –∏ RGB –ø–∞–ª–∏—Ç—Ä—É
                # –ü–µ—Ä–µ–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é apply_fixed_palette –∏–∑ –ª–æ–≥–∏–∫–∏
                result_image_chw = apply_dithering(
                    image_chw, # –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–ª—è –æ—à–∏–±–∫–∏ —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å float RGB [0,1]
                    palette_rgb,
                    dither_pattern,
                    dither_strength,
                    color_distance_threshold,
                    apply_fixed_palette,
                )
            except Exception as e:
                 print(f"[ApplyPaletteNode] Error during dithering: {e}")
                 traceback.print_exc()
                 print("  - Falling back to non-dithered palette application (RGB).")
                 # Fallback –Ω–∞ –æ–±—ã—á–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–∞–ª–∏—Ç—Ä—ã –≤ RGB
                 color_space = "RGB" # –ú–µ–Ω—è–µ–º color_space –Ω–∞ RGB –¥–ª—è fallback
                 use_dither = False # –û—Ç–∫–ª—é—á–∞–µ–º —Ñ–ª–∞–≥ –¥–∏–∑–µ—Ä–∏–Ω–≥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±–ª–æ–∫–∞ else

        if not use_dither:
            # --- –ü—Ä–æ—Å—Ç–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –ø–∞–ª–∏—Ç—Ä–æ–π (–±–µ–∑ –¥–∏–∑–µ—Ä–∏–Ω–≥–∞) ---
            print(f"  - Applying palette using nearest neighbor in {color_space} space (Dithering disabled or failed).")
            try:
                # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø–∞–ª–∏—Ç—Ä—É –≤ —Ü–µ–ª–µ–≤–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ
                img_in_space = to_quantize_space(image_chw, color_space)
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGB –ø–∞–ª–∏—Ç—Ä—É –≤ color_space
                palette_expanded = palette_rgb.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)
                palette_in_space = to_quantize_space(palette_expanded, color_space).squeeze()
                if palette_in_space.ndim == 1: palette_in_space = palette_in_space.unsqueeze(0)

                # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–∞–ª–∏—Ç—Ä—É (–ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–≥–æ) –≤ —ç—Ç–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ
                quantized_img_in_space = apply_fixed_palette(img_in_space, palette_in_space)

                # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –≤ RGB
                result_image_chw = from_quantize_space(quantized_img_in_space, color_space)

            except Exception as e:
                print(f"[ApplyPaletteNode] Error during palette application in {color_space}: {e}")
                traceback.print_exc()
                result_image_chw = image_chw # Fallback

        # --- –í—ã—Ö–æ–¥ ---
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç ComfyUI (B, H, W, C)
        final_image_hwc = result_image_chw.permute(0, 2, 3, 1).clamp(0, 1)

        return (final_image_hwc,)


# --- –£–∑–µ–ª –ó–∞–º–µ–Ω—ã –¶–≤–µ—Ç–æ–≤ –ü–∞–ª–∏—Ç—Ä—ã ---
class ReplacePaletteColorsNode:
    CATEGORY = "üòé SnJake/PixelArt/Utils" # –£—Ç–æ—á–Ω–∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    FUNCTION = "replace_colors"
    RETURN_TYPES = ("IMAGE",)

    SORT_METHODS = ["None", "Luminance", "Hue", "Saturation", "Value"]

    @classmethod
    def INPUT_TYPES(cls):
        if not LOGIC_IMPORTED:
             return {"required": {"error": ("STRING", {"default": "PixelArt logic failed to load", "forceInput": True, "hidden":True})}}

        return {
            "required": {
                "image": ("IMAGE", {"tooltip": "–ö–≤–∞–Ω—Ç–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ —Å –Ω–µ–±–æ–ª—å—à–∏–º –∫–æ–ª-–≤–æ–º —Ü–≤–µ—Ç–æ–≤)."}),
                "source_palette": (PALETTE, {"tooltip": "–ò—Å—Ö–æ–¥–Ω–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ([N, 3] RGB 0-1)."}),
                "replacement_palette": (PALETTE, {"tooltip": "–ü–∞–ª–∏—Ç—Ä–∞ –¥–æ–Ω–æ—Ä–∞ ([M, 3] RGB 0-1)."}),
                "sort_method": (cls.SORT_METHODS, {"default": "Luminance", "tooltip": "–ú–µ—Ç–æ–¥ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –ø–∞–ª–∏—Ç—Ä –ø–µ—Ä–µ–¥ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º —Ü–≤–µ—Ç–æ–≤ 1-–∫-1."}),
                "mismatch_handling": (["Error", "Trim Replacement", "Repeat Replacement"], {"default": "Trim Replacement", "tooltip": "–ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª-–≤–∞ —Ü–≤–µ—Ç–æ–≤ –ø–æ—Å–ª–µ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏."}),
                "tolerance": ("FLOAT", {"default": 0.01, "min": 0.0, "max": 0.5, "step": 0.001, "round":0.0001, "tooltip": "–î–æ–ø—É—Å–∫ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ü–≤–µ—Ç–æ–≤ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ª–∏—Ç—Ä—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."})
            }
        }

    def _sort_palette(self, palette_rgb, method, device):
        """–°–æ—Ä—Ç–∏—Ä—É–µ—Ç –ø–∞–ª–∏—Ç—Ä—É [N, 3] RGB 0-1 –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –º–µ—Ç–æ–¥—É."""
        if method == "None" or palette_rgb is None or palette_rgb.shape[0] <= 1:
            return palette_rgb, torch.arange(palette_rgb.shape[0], device=device) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –∏–Ω–¥–µ–∫—Å—ã

        palette_rgb = palette_rgb.float().to(device) # –†–∞–±–æ—Ç–∞–µ–º —Å float –Ω–∞ –Ω—É–∂–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ

        try:
            if method == "Luminance":
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Y –∏–∑ YCbCr Kornia –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
                # Kornia –æ–∂–∏–¥–∞–µ—Ç (B, C, H, W), –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏—è
                palette_ycbcr = kc.rgb_to_ycbcr(palette_rgb.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)).squeeze()
                if palette_ycbcr.ndim == 1: palette_ycbcr = palette_ycbcr.unsqueeze(0)
                values_to_sort = palette_ycbcr[:, 0] # Y –∫–∞–Ω–∞–ª
            elif method in ["Hue", "Saturation", "Value"]:
                 palette_hsv = kc.rgb_to_hsv(palette_rgb.unsqueeze(0).unsqueeze(-1).unsqueeze(-1)).squeeze()
                 if palette_hsv.ndim == 1: palette_hsv = palette_hsv.unsqueeze(0)
                 idx = {"Hue": 0, "Saturation": 1, "Value": 2}[method]
                 values_to_sort = palette_hsv[:, idx]
                 # –î–ª—è Hue (—Ü–∏–∫–ª–∏—á–Ω—ã–π), —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∏–¥–µ–∞–ª—å–Ω–æ–π, –Ω–æ —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
            else: # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥
                print(f"Warning: Unknown sort method '{method}'. Sorting skipped.")
                return palette_rgb, torch.arange(palette_rgb.shape[0], device=device)

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏
            sorted_indices = torch.argsort(values_to_sort)
            sorted_palette = palette_rgb[sorted_indices]
            return sorted_palette, sorted_indices

        except Exception as e:
            print(f"Error during palette sorting by {method}: {e}")
            traceback.print_exc()
            print("Sorting skipped due to error.")
            return palette_rgb, torch.arange(palette_rgb.shape[0], device=device)


    def replace_colors(self, image, source_palette, replacement_palette, sort_method, mismatch_handling, tolerance):
        device = image.device if isinstance(image, torch.Tensor) else get_torch_device()
        print(f"[ReplacePalette] Input image device: {image.device}, Target device: {device}")

        # --- –ü—Ä–æ–≤–µ—Ä–∫–∏ –≤—Ö–æ–¥–æ–≤ ---
        if not LOGIC_IMPORTED: return (image,) # –ï—Å–ª–∏ –ª–æ–≥–∏–∫–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        if image is None: return (None,)
        if source_palette is None or not isinstance(source_palette, torch.Tensor) or source_palette.ndim != 2 or source_palette.shape[1] != 3:
            print("[ReplacePalette] Error: Invalid source_palette.")
            return (image,)
        if replacement_palette is None or not isinstance(replacement_palette, torch.Tensor) or replacement_palette.ndim != 2 or replacement_palette.shape[1] != 3:
            print("[ReplacePalette] Error: Invalid replacement_palette.")
            return (image,)
        if tolerance < 0: tolerance = 0.0

        # --- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ---
        image = image.to(device)
        source_palette = source_palette.float().clamp(0, 1).to(device)
        replacement_palette = replacement_palette.float().clamp(0, 1).to(device)

        n_source_orig = source_palette.shape[0]
        n_replace_orig = replacement_palette.shape[0]

        print(f"[ReplacePalette] Original counts: Source={n_source_orig}, Replacement={n_replace_orig}. Sort: {sort_method}")

        # --- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–∞–ª–∏—Ç—Ä ---
        sorted_source_palette, _ = self._sort_palette(source_palette, sort_method, device)
        sorted_replacement_palette, _ = self._sort_palette(replacement_palette, sort_method, device) # –ò–Ω–¥–µ–∫—Å—ã –¥–æ–Ω–æ—Ä–∞ –Ω–µ –Ω—É–∂–Ω—ã

        n_source = sorted_source_palette.shape[0]
        n_replace = sorted_replacement_palette.shape[0]

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ü–≤–µ—Ç–æ–≤ –ü–û–°–õ–ï —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ ---
        final_replacement_palette = sorted_replacement_palette
        if n_source != n_replace:
            print(f"Warning: Sorted palette size mismatch ({n_source} vs {n_replace}). Handling: {mismatch_handling}")
            if mismatch_handling == "Error":
                print("ERROR: Palette sizes must match.")
                return (image,) # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –ø—Ä–∏ –æ—à–∏–±–∫–µ
            elif mismatch_handling == "Trim Replacement":
                final_replacement_palette = sorted_replacement_palette[:n_source]
            elif mismatch_handling == "Repeat Replacement":
                if n_replace == 0:
                    print("ERROR: Replacement palette is empty.")
                    return (image,)
                repeat_times = math.ceil(n_source / n_replace) # –°–∫–æ–ª—å–∫–æ —Ä–∞–∑ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
                final_replacement_palette = sorted_replacement_palette.repeat(repeat_times, 1)[:n_source]

            if final_replacement_palette.shape[0] != n_source:
                 print(f"ERROR: Failed to handle palette mismatch correctly. Sizes: {n_source} vs {final_replacement_palette.shape[0]}")
                 return (image,) # –û—à–∏–±–∫–∞

        if n_source == 0 or final_replacement_palette.shape[0] == 0:
             print("Error: One or both palettes are empty after handling mismatch.")
             return (image,)

        # --- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã –∑–∞–º–µ–Ω –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ---
        image_chw = image.permute(0, 3, 1, 2).float() # B, C, H, W
        B, C, H, W = image_chw.shape
        output_image_chw = image_chw.clone() # –†–∞–±–æ—Ç–∞–µ–º —Å –∫–æ–ø–∏–µ–π

        print(f"Applying replacement map ({n_source} colors) with tolerance {tolerance}...")
        replaced_count = 0
        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ *–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π* –∏—Å—Ö–æ–¥–Ω–æ–π –ø–∞–ª–∏—Ç—Ä–µ
        for i, src_color_tensor in enumerate(sorted_source_palette):
            replacement_color_tensor = final_replacement_palette[i]

            # –ù–∞—Ö–æ–¥–∏–º –ø–∏–∫—Å–µ–ª–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç—Ç–æ–º—É –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ü–≤–µ—Ç—É —Å –¥–æ–ø—É—Å–∫–æ–º
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–≤–∫–ª–∏–¥–æ–≤–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∏–ª–∏ L1 –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏? L1 (sum(abs(diff))) –ø—Ä–æ—â–µ.
            diff = torch.abs(image_chw - src_color_tensor.view(1, C, 1, 1)) # B, C, H, W
            # mask = torch.sum(diff, dim=1) < tolerance # –°—É–º–º–∞ –∞–±—Å–æ–ª—é—Ç–Ω—ã—Ö —Ä–∞–∑–Ω–æ—Å—Ç–µ–π < tolerance?
            # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ - L2 —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–∫–æ—Ä–µ–Ω—å –Ω–µ –Ω—É–∂–µ–Ω, —Å—Ä–∞–≤–Ω–∏–º –∫–≤–∞–¥—Ä–∞—Ç)
            dist_sq = torch.sum(diff**2, dim=1) # B, H, W
            mask = dist_sq < (tolerance**2) # –ú–∞—Å–∫–∞ [B, H, W]

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∑–∞–º–µ–Ω—É —Ç–∞–º, –≥–¥–µ –º–∞—Å–∫–∞ True
            # .unsqueeze(1) –¥–æ–±–∞–≤–ª—è–µ—Ç –æ–±—Ä–∞—Ç–Ω–æ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ –¥–ª—è –º–∞—Å–∫–∏
            output_image_chw = torch.where(mask.unsqueeze(1).expand_as(output_image_chw),
                                           replacement_color_tensor.view(1, C, 1, 1).expand_as(output_image_chw),
                                           output_image_chw)
            replaced_count += mask.sum().item() # –°—á–∏—Ç–∞–µ–º –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏

        print(f"Replacement finished. Approximately {replaced_count} pixels potentially replaced.")


        # --- –í—ã—Ö–æ–¥ ---
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç ComfyUI (B, H, W, C)
        final_image_hwc = output_image_chw.permute(0, 2, 3, 1).clamp(0, 1)

        return (final_image_hwc,)
