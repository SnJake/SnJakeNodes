import os
import sys
import torch
import numpy as np
from PIL import Image

# –î–æ–±–∞–≤–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –Ω–æ–¥–æ–π –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ 'sam2'
sys.path.append(os.path.dirname(__file__))

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ ComfyUI
import folder_paths
from comfy.utils import ProgressBar

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ SAM-2 –∏ –¥—Ä—É–≥–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from sam2 import sam2_image_predictor
    from sam2 import build_sam
    from sam2.build_sam import build_sam2
    from safetensors.torch import load_file as load_safetensors
except ImportError as e:
    print(f"SnJakeNodes Error: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É SAM2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ 'sam2' –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –Ω–æ–¥—ã –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (hydra-core, omegaconf, safetensors). –û—à–∏–±–∫–∞: {e}")


# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

# –£–∫–∞–∑—ã–≤–∞–µ–º ComfyUI, –≥–¥–µ –∏—Å–∫–∞—Ç—å –º–æ–¥–µ–ª–∏ SAM-2
SAM2_MODEL_DIR = os.path.join(folder_paths.models_dir, "sam2")
folder_paths.add_model_folder_path("sam2", SAM2_MODEL_DIR)

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π —Å —Ñ–∞–π–ª–∞–º–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
MODEL_CONFIG_MAP = {
    "hiera_tiny": "sam2.1_hiera_t.yaml",
    "hiera_small": "sam2.1_hiera_s.yaml",
    "hiera_base_plus": "sam2.1_hiera_b+.yaml",
    "hiera_large": "sam2.1_hiera_l.yaml",
}

def get_sam2_model_names():
    """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å –º–æ–¥–µ–ª—è–º–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤."""
    if not os.path.exists(SAM2_MODEL_DIR):
        os.makedirs(SAM2_MODEL_DIR)
        return []
    return [f for f in os.listdir(SAM2_MODEL_DIR) if f.endswith((".pt", ".safetensors"))]

def tensor_to_numpy_image(tensor):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–µ–Ω–∑–æ—Ä (B, H, W, C) –≤ –º–∞—Å—Å–∏–≤ numpy (H, W, C) uint8."""
    if tensor.ndim == 3:
        tensor = tensor.unsqueeze(0)
    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑ float [0,1] –≤ uint8 [0,255]
    img = tensor.cpu().numpy()[0]
    return np.clip(img * 255, 0, 255).astype(np.uint8)


# --- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–¥ ---

class Sam2Loader:
    """–ù–æ–¥–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ SAM-2 –∏ –µ–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "model_name": (get_sam2_model_names(),),
                "device": (["cuda", "cpu"],),
            }
        }

    RETURN_TYPES = ("SAM2_MODEL",)
    RETURN_NAMES = ("sam2_model",)
    FUNCTION = "load_model"
    CATEGORY = "üòé SnJake/SAM2"

    def load_model(self, model_name, device):
        ckpt_path = os.path.join(SAM2_MODEL_DIR, model_name)
        if not os.path.exists(ckpt_path):
            raise FileNotFoundError(f"–ß–µ–∫–ø–æ–∏–Ω—Ç –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {ckpt_path}")

        # –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        config_name = next((v for k, v in MODEL_CONFIG_MAP.items() if k in model_name), None)
        if config_name is None:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏: {model_name}")

        config_file_path = os.path.join(os.path.dirname(__file__), "sam2", "configs", "sam2.1", config_name)
        if not os.path.exists(config_file_path):
            raise FileNotFoundError(f"–§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_file_path}")

        print(f"SnJake SAM2: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ '{model_name}' —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π '{config_name}'")

        # –ó–∞–≥—Ä—É–∑–∫–∞ state_dict –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if model_name.endswith(".safetensors"):
            sd = load_safetensors(ckpt_path, device="cpu")
        else:
            sd = torch.load(ckpt_path, map_location="cpu")

        model_sd = sd.get("model", sd)

        # --- –ö–∞—Å—Ç–æ–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ ---
        # –ú—ã –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é –∑–∞–≥—Ä—É–∑–∫–∏ –≤ build_sam,
        # —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—à —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π state_dict.
        original_load_checkpoint = build_sam._load_checkpoint
        def new_load_checkpoint(model, ckpt_path):
            missing_keys, unexpected_keys = model.load_state_dict(model_sd, strict=False)
            if missing_keys:
                print(f"SAM2 Warning (–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∫–ª—é—á–∏): {missing_keys}")
            if unexpected_keys:
                print(f"SAM2 Warning (–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –∫–ª—é—á–∏): {unexpected_keys}")
            print("SnJake SAM2: State dict —á–µ–∫–ø–æ–∏–Ω—Ç–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

        build_sam._load_checkpoint = new_load_checkpoint

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º hydra –¥–ª—è —á—Ç–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ –∏–Ω—Å—Ç–∞–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        from hydra import initialize_config_dir, compose
        from omegaconf import OmegaConf

        config_dir = os.path.dirname(config_file_path)
        with initialize_config_dir(config_dir=os.path.abspath(config_dir), version_base=None):
            cfg = compose(config_name=os.path.basename(config_file_path))
            OmegaConf.resolve(cfg)
            
            # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–∑–æ–≤–µ—Ç –Ω–∞—à new_load_checkpoint
            sam_model = build_sam2(
                config_file=config_file_path,
                ckpt_path=ckpt_path, # —Ñ–æ—Ä–º–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–µ–º, –Ω–æ –æ–Ω –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
                device=device,
                mode="eval",
            )
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
        build_sam._load_checkpoint = original_load_checkpoint
        print("SnJake SAM2: –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
        return (sam_model,)


class Sam2ImageInference:
    """–ù–æ–¥–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å –ø–æ–º–æ—â—å—é SAM-2."""
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "sam2_model": ("SAM2_MODEL",),
                "image": ("IMAGE",),
                "positive_points": ("MASK",),
                "negative_points": ("MASK",),
                "threshold": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}),
                "multimask_output": ("BOOLEAN", {"default": True}),
            }
        }

    RETURN_TYPES = ("MASK",)
    FUNCTION = "predict"
    CATEGORY = "üòé SnJake/SAM2"

    def predict(self, sam2_model, image, positive_points, negative_points, threshold, multimask_output):
        predictor = sam2_image_predictor.SAM2ImagePredictor(
            sam_model=sam2_model,
            mask_threshold=threshold,
        )
        
        img_np = tensor_to_numpy_image(image)
        
        print("SnJake SAM2: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞...")
        predictor.set_image(img_np)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ (—Ç–æ—á–µ–∫)
        pos_coords = (positive_points[0] > 0).nonzero(as_tuple=False).cpu().numpy()[:, [1, 0]]
        neg_coords = (negative_points[0] > 0).nonzero(as_tuple=False).cpu().numpy()[:, [1, 0]]

        if pos_coords.shape[0] == 0 and neg_coords.shape[0] == 0:
            print("SnJake SAM2 Warning: –¢–æ—á–∫–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–∞—è –º–∞—Å–∫–∞.")
            h, w, _ = img_np.shape
            return (torch.zeros((1, h, w), dtype=torch.float32, device="cpu"),)

        point_coords = np.concatenate([pos_coords, neg_coords], axis=0) if neg_coords.size > 0 else pos_coords
        pos_labels = np.ones(pos_coords.shape[0], dtype=int)
        neg_labels = np.zeros(neg_coords.shape[0], dtype=int)
        point_labels = np.concatenate([pos_labels, neg_labels], axis=0)
        
        print(f"SnJake SAM2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å {pos_coords.shape[0]} –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º–∏ –∏ {neg_coords.shape[0]} –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º–∏ —Ç–æ—á–∫–∞–º–∏...")
        masks_np, iou_preds, _ = predictor.predict(
            point_coords=point_coords,
            point_labels=point_labels,
            multimask_output=multimask_output,
            return_logits=False, # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∂–µ –±–∏–Ω–∞—Ä–Ω—ã–µ –º–∞—Å–∫–∏
        )

        # masks_np –∏–º–µ–µ—Ç —Ñ–æ—Ä–º—É (C, H, W), –≥–¥–µ C - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–∞—Å–æ–∫
        # –í—ã–±–∏—Ä–∞–µ–º –º–∞—Å–∫—É —Å –Ω–∞–∏–ª—É—á—à–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º IoU
        best_mask_idx = np.argmax(iou_preds)
        final_mask_np = masks_np[best_mask_idx]

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –º–∞—Å–∫—É –≤ —Ç–µ–Ω–∑–æ—Ä float, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç ComfyUI
        final_mask_tensor = torch.from_numpy(final_mask_np.astype(np.float32)).unsqueeze(0)
        
        return (final_mask_tensor,)
