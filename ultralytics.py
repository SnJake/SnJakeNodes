# file: ultralytics.py

from pathlib import Path
from typing import List, Dict

import torch
import numpy as np
from ultralytics import YOLO
from PIL import Image, ImageDraw, ImageFont

import folder_paths
from server import PromptServer

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_ALLOWED_EXTS = {".pt", ".safetensors", ".onnx"}

def _root() -> Path:
    return Path(folder_paths.base_path) / "models" / "ultralytics"

def _scan(kind: str) -> List[str]:
    d = _root() / kind
    if not d.exists():
        return []
    return sorted(
        str(p.relative_to(_root()).as_posix())
        for p in d.rglob("*")
        if p.suffix.lower() in _ALLOWED_EXTS and p.is_file()
    )

def _resolve(r: str) -> str:
    return str((_root() / r).resolve())

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ComfyUI custom types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _Any(str):
    def __eq__(self, other):
        return True
    __ne__ = lambda self, other: False

YOLO_MODEL = _Any("YOLO_MODEL")
BBOX_TYPE  = _Any("BBOX")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ loader node â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class YoloModelLoader:
    CATEGORY = "ğŸ˜ SnJake/YOLO"
    FUNCTION = "load"
    RETURN_TYPES = (YOLO_MODEL, "STRING")
    RETURN_NAMES = ("model", "model_path")

    @classmethod
    def INPUT_TYPES(cls):
        opts = _scan("bbox") + _scan("segm") or ["<no models>"]
        return {
            "required": {
                "task": (["bbox", "segm"], {"default": "bbox"}),
                "model_name": (opts, {"default": opts[0]}),
                "device": (["auto", "cuda", "cpu"], {"default": "auto"}),
            }
        }

    def load(self, task: str, model_name: str, device: str = "auto"):
        if model_name.startswith("<no models"):
            raise FileNotFoundError("ĞŸĞ°Ğ¿ĞºĞ° models/ultralytics Ğ¿ÑƒÑÑ‚Ğ°")
        if not model_name.startswith(f"{task}/"):
            PromptServer.instance.send_sync("yolo_loader.warn", {"msg": f"'{model_name}' Ğ½Ğµ Ğ² Ğ¿Ğ¾Ğ´Ğ¿Ğ°Ğ¿ĞºĞµ '{task}/' â€“ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑŒÑ‚Ğµ, Ñ‚Ğ° Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ."})
        model = YOLO(_resolve(model_name), task="detect" if task == "bbox" else "segment")
        if device != "auto":
            model.to(device)
        return (model, model_name)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ inference node â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class YoloInference:
    CATEGORY = "ğŸ˜ SnJake/YOLO"
    FUNCTION = "infer"
    RETURN_TYPES = ("IMAGE", "MASK", BBOX_TYPE)
    RETURN_NAMES = ("image_with_bboxes", "mask", "bboxes")

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {}),
                "model": (YOLO_MODEL, {"forceInput": True}),
                "conf": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}), # ĞŸĞ¾Ğ²Ñ‹ÑĞ¸Ğ» ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
                "iou": ("FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}), # ĞŸĞ¾Ğ²Ñ‹ÑĞ¸Ğ» ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ
                "filter_classes": ("STRING", {"default": "", "placeholder": "commaâ€‘separated names"}),
                "mask_bbox_fuzz": ("INT", {"default": 0, "min": 0, "max": 32}), # Ğ£Ğ±Ñ€Ğ°Ğ» ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ñ€Ğ°Ğ·Ğ¼Ñ‹Ñ‚Ğ¸Ğµ
            }
        }

    @staticmethod
    def _tensor_to_uint8(img: torch.Tensor):
        return (img * 255).clamp(0, 255).byte().cpu().numpy()

    @staticmethod
    def _boxes_to_mask(h: int, w: int, boxes: List[Dict], fuzz: int = 0) -> torch.Tensor:
        mask = torch.zeros((h, w), dtype=torch.bool)
        for b in boxes:
            x1, y1, x2, y2 = map(int, b["xyxy"])
            x1 = max(0, x1 - fuzz)
            y1 = max(0, y1 - fuzz)
            x2 = min(w, x2 + fuzz)
            y2 = min(h, y2 + fuzz)
            mask[y1:y2, x1:x2] = True
        return mask

    @staticmethod
    def _draw_boxes(img_tensor, boxes):
        img_np = (img_tensor.cpu().numpy() * 255).astype(np.uint8)
        img_pil = Image.fromarray(img_np)
        draw = ImageDraw.Draw(img_pil)
        try:
            font = ImageFont.truetype("arial.ttf", 20)
        except IOError:
            font = ImageFont.load_default(size=20)

        for b in boxes:
            xyxy = b["xyxy"]
            label = f"{b['class_name']} {b['confidence']:.2f}"
            draw.rectangle(xyxy, outline="red", width=3)
            
            text_bbox = draw.textbbox((0, 0), label, font=font)
            text_w, text_h = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]
            
            text_y = xyxy[1] - text_h - 5
            if text_y < 0:
                text_y = xyxy[1] + 2

            draw.rectangle([xyxy[0], text_y, xyxy[0] + text_w + 4, text_y + text_h + 4], fill="red")
            draw.text((xyxy[0] + 2, text_y + 2), label, fill="white", font=font)
            
        return torch.from_numpy(np.array(img_pil).astype(np.float32) / 255.0)

    def infer(self, image, model, conf: float, iou: float, filter_classes: str, mask_bbox_fuzz: int):
        if not hasattr(model, "predict"):
            raise TypeError("Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğµ ÑĞ²Ğ»ÑÑÑ‚ÑÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ Ultralytics YOLO")

        allowed = {s.strip() for s in filter_classes.split(",") if s.strip()}
        imgs_np = [self._tensor_to_uint8(im) for im in image]
        
        results = model.predict(imgs_np, conf=conf, iou=iou, stream=False, verbose=False)

        batch_boxes: List[List[Dict]] = []
        batch_mask: List[torch.Tensor] = []
        drawn_images: List[torch.Tensor] = []

        for i, res in enumerate(results):
            boxes_cur = []
            keep_idx = []
            if res.boxes is not None:
                for idx, (xyxy, conf_, cls_) in enumerate(zip(res.boxes.xyxy.cpu(), res.boxes.conf.cpu(), res.boxes.cls.cpu())):
                    cls_name = model.names[int(cls_)]
                    if allowed and cls_name not in allowed:
                        continue
                    keep_idx.append(idx)
                    boxes_cur.append({
                        "xyxy": xyxy.tolist(),
                        "confidence": float(conf_),
                        "class_id": int(cls_),
                        "class_name": cls_name,
                    })
            batch_boxes.append(boxes_cur)
            
            drawn_images.append(self._draw_boxes(image[i], boxes_cur))

            if getattr(res, "masks", None) is not None and keep_idx:
                m = torch.any(res.masks.data[torch.tensor(keep_idx, device=res.masks.data.device)].float() > 0.5, dim=0).cpu()
            else:
                h, w = res.orig_shape
                m = self._boxes_to_mask(h, w, boxes_cur, mask_bbox_fuzz)
            batch_mask.append(m)

        images_out = torch.stack(drawn_images, dim=0)
        
        if not batch_mask: # Ğ•ÑĞ»Ğ¸ Ğ¼Ğ°ÑĞ¾Ğº Ğ½ĞµÑ‚, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ğ¾Ğ¹ Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€
             masks_out = torch.zeros((image.shape[0], image.shape[1], image.shape[2]), dtype=torch.float32)
        else:
             masks_out = torch.stack(batch_mask, dim=0).float()

        return (images_out, masks_out, batch_boxes)

